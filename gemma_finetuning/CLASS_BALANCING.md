# –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –ö–ª–∞—Å—Å–æ–≤ –¥–ª—è Fine-tuning

## üéØ –ü—Ä–æ–±–ª–µ–º–∞

–í –¥–∞—Ç–∞—Å–µ—Ç–µ —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:
- **–¢–æ–ø –∫–ª–∞—Å—Å (10151)**: 101,385 –ø—Ä–∏–º–µ—Ä–æ–≤ (26%)
- **–†–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã**: –≤—Å–µ–≥–æ 8-20 –ø—Ä–∏–º–µ—Ä–æ–≤
- **–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ**: 26% vs 0.01% (~2600x —Ä–∞–∑–Ω–∏—Ü–∞!)

–ë–µ–∑ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç:
- ‚úÖ –•–æ—Ä–æ—à–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —á–∞—Å—Ç—ã–µ –∫–ª–∞—Å—Å—ã (80101, 10151, 21601)
- ‚ùå –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã
- ‚ùå –í—ã—Å–æ–∫–∞—è –æ–±—â–∞—è accuracy, –Ω–æ –ø–ª–æ—Ö–∞—è per-class performance

## ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

### 1. **Focal Loss** 
```python
FOCAL_LOSS_GAMMA = 2.0  # –§–æ–∫—É—Å –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
```

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
- –°–Ω–∏–∂–∞–µ—Ç –≤–µ—Å –¥–ª—è –ª–µ–≥–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –≤–µ—Å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö/–æ—à–∏–±–æ—á–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- Gamma=2.0 - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- ‚úÖ –°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (>100x)
- ‚úÖ –ú–Ω–æ–≥–æ –∫–ª–∞—Å—Å–æ–≤ (>50)
- ‚ùå –í—ã–∫–ª—é—á–∏—Ç—å (gamma=0) –¥–ª—è balanced –¥–∞–Ω–Ω—ã—Ö

### 2. **Class Weights**
```python
USE_CLASS_WEIGHTS = True
```

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
- –í—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Å–∞: `w_i = n_samples / (n_classes * n_samples_i)`
- –†–µ–¥–∫–∏–º –∫–ª–∞—Å—Å–∞–º –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è –±–æ–ª—å—à–∏–π –≤–µ—Å –≤ loss
- –ú–æ–¥–µ–ª—å "—à—Ç—Ä–∞—Ñ—É–µ—Ç—Å—è" —Å–∏–ª—å–Ω–µ–µ –∑–∞ –æ—à–∏–±–∫–∏ –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö

**–í–µ—Å–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:**
```
outputs/class_weights.json
```

### 3. **Weighted Random Sampler** (–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω, –Ω–æ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω)
```python
USE_WEIGHTED_SAMPLER = True  # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ trainer
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ DataLoader.
–í —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —á–µ—Ä–µ–∑ loss function.

### 4. **–£–ª—É—á—à–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**

#### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- **Accuracy**: –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–º–∞–Ω—á–∏–≤–∞ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ)
- **F1 Macro**: –°—Ä–µ–¥–Ω–µ–µ F1 –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
- **F1 Micro**: F1 —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (–±–ª–∏–∑–∫–æ –∫ accuracy)

#### –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏:
```python
metric_for_best_model="eval_f1_macro"  # –í–º–µ—Å—Ç–æ eval_loss
greater_is_better=True
```

**–ü–æ—á–µ–º—É F1 Macro?**
- ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ
- ‚úÖ –ù–µ –¥–∞–µ—Ç –º–æ–¥–µ–ª–∏ "—Å—Ö–∏—Ç—Ä–∏—Ç—å" –∑–∞ —Å—á–µ—Ç —á–∞—Å—Ç—ã—Ö –∫–ª–∞—Å—Å–æ–≤
- ‚úÖ –õ—É—á—à–µ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –ø–æ–ª—å–∑—É –º–æ–¥–µ–ª–∏

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –í –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è:
```bash
tensorboard --logdir gemma_finetuning/logs
```

**–°–º–æ—Ç—Ä–µ—Ç—å –Ω–∞:**
- `eval_f1_macro` - –¥–æ–ª–∂–µ–Ω —Ä–∞—Å—Ç–∏
- `eval_f1_micro` vs `eval_f1_macro` - —Ä–∞–∑–Ω–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å
- `train_loss` vs `eval_loss` - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ overfitting

### –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:
```bash
python scripts/evaluate.py
```

–ü–æ–∫–∞–∂–µ—Ç:
- Per-class precision/recall/F1
- Confusion matrix
- –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∫–ª–∞—Å—Å—ã

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö:
```python
FOCAL_LOSS_GAMMA = 1.5  # –£–º–µ–Ω—å—à–∏—Ç—å focal loss
USE_CLASS_WEIGHTS = False  # –í—ã–∫–ª—é—á–∏—Ç—å –≤–µ—Å–∞
```

### –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã:
```python
FOCAL_LOSS_GAMMA = 3.0  # –£–≤–µ–ª–∏—á–∏—Ç—å focal loss
MIN_SAMPLES_PER_CLASS = 50  # –ü–æ–¥–Ω—è—Ç—å –ø–æ—Ä–æ–≥ –≤ prepare_data.py
```

### –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏:
```python
BATCH_SIZE = 1  # –£–º–µ–Ω—å—à–∏—Ç—å batch
GRADIENT_ACCUMULATION = 16  # –£–≤–µ–ª–∏—á–∏—Ç—å accumulation
MAX_SEQ_LENGTH = 256  # –£–º–µ–Ω—å—à–∏—Ç—å –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```

## üéì –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –•–æ—Ä–æ—à–æ:
- **F1 Macro**: 0.60-0.80
- **F1 Micro**: 0.75-0.90
- **Accuracy**: 0.75-0.90

### –ü–ª–æ—Ö–æ (–º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–∏–ª–∞—Å—å):
- **F1 Macro** < 0.50
- **F1 Macro** << **F1 Micro** (–±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞)
- –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö < 0.10

## üìù –§–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:
```
outputs/class_weights.json          # –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
models/<run_name>/
  ‚îú‚îÄ‚îÄ adapter_config.json           # LoRA –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
  ‚îú‚îÄ‚îÄ adapter_model.bin             # –û–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞
  ‚îú‚îÄ‚îÄ training_config.json          # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
  ‚îî‚îÄ‚îÄ evaluation_results.json       # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
logs/<run_name>/
  ‚îî‚îÄ‚îÄ events.out.tfevents.*         # TensorBoard –ª–æ–≥–∏
```

## üî¨ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ (–¥–ª—è –±—É–¥—É—â–µ–≥–æ)

### 1. Data Augmentation
- –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ PaymentComment
- –°–∏–Ω–æ–Ω–∏–º—ã –∏ –≤–∞—Ä–∏–∞—Ü–∏–∏

### 2. Oversampling —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤
- SMOTE (–¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ —Å–ª–æ–∂–Ω–æ)
- –ü—Ä–æ—Å—Ç–æ–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

### 3. Two-stage training
- –°–Ω–∞—á–∞–ª–∞ –Ω–∞ —á–∞—Å—Ç—ã—Ö –∫–ª–∞—Å—Å–∞—Ö
- –ü–æ—Ç–æ–º fine-tune –Ω–∞ —Ä–µ–¥–∫–∏—Ö

### 4. Hierarchical classification
- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–¥–æ–≤
- –°–Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≥—Ä—É–ø–ø—É, –ø–æ—Ç–æ–º —Ç–æ—á–Ω—ã–π –∫–æ–¥

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—É–∂–µ —Å–¥–µ–ª–∞–Ω–æ)
python scripts/prepare_data.py

# 2. –û–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
python scripts/train_qlora.py

# 3. –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
python scripts/evaluate.py

# 4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ)
tensorboard --logdir logs
```

## üìö –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

- [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)
- [Class Imbalance in Machine Learning](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)


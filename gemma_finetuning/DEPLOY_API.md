# üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ API –Ω–∞ –¥—Ä—É–≥–æ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ

## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞:

### Hardware:
- ‚úÖ **GPU:** NVIDIA —Å –º–∏–Ω–∏–º—É–º 6 GB VRAM (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 8+ GB)
- ‚úÖ **CUDA:** 11.8+ –∏–ª–∏ 12.x
- ‚úÖ **RAM:** 8 GB –º–∏–Ω–∏–º—É–º
- ‚úÖ **–î–∏—Å–∫:** 25-30 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞

### Software:
- Python 3.10+
- CUDA toolkit
- conda –∏–ª–∏ venv

## üì¶ –ß–¢–û –ù–£–ñ–ù–û –°–ö–û–ü–ò–†–û–í–ê–¢–¨:

```bash
gemma_finetuning/
‚îú‚îÄ‚îÄ api_server.py              ‚Üê API —Å–µ—Ä–≤–µ—Ä
‚îú‚îÄ‚îÄ start_api.sh               ‚Üê –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îî‚îÄ‚îÄ gemma_qlora_*/
‚îÇ       ‚îî‚îÄ‚îÄ checkpoint-XXXX/   ‚Üê –õ–Æ–ë–û–ô checkpoint
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ purpose_codes.txt      ‚Üê –°–ª–æ–≤–∞—Ä—å –∫–æ–¥–æ–≤
‚îî‚îÄ‚îÄ requirements.txt           ‚Üê –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```

## üîß –£–°–¢–ê–ù–û–í–ö–ê –ù–ê –ù–û–í–û–ú –ö–û–ú–ü–¨–Æ–¢–ï–†–ï:

### 1. –°–æ–∑–¥–∞–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:

```bash
# –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
mkdir -p ~/gemma_api
cd ~/gemma_api

# –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
conda create -n gemma_api python=3.10 -y
conda activate gemma_api

# –ò–õ–ò —Å venv
python3 -m venv venv
source venv/bin/activate
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:

```bash
# PyTorch —Å CUDA (–≤–∞–∂–Ω–æ!)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
pip install transformers accelerate bitsandbytes peft
pip install fastapi uvicorn datasets

# –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### 3. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª—ã:

```bash
# –° —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞ –Ω–∞ –Ω–æ–≤—ã–π (—á–µ—Ä–µ–∑ scp –∏–ª–∏ —Ñ–ª–µ—à–∫—É)
scp -r gemma_finetuning/api_server.py USER@NEW_PC:~/gemma_api/
scp -r gemma_finetuning/outputs/ USER@NEW_PC:~/gemma_api/
scp -r gemma_finetuning/data/purpose_codes.txt USER@NEW_PC:~/gemma_api/data/
```

### 4. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—É—Ç–∏ –≤ api_server.py:

–û—Ç–∫—Ä–æ–π—Ç–µ `api_server.py` –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏:

```python
# –°—Ç—Ä–æ–∫–∞ 17-18
BASE_MODEL = "google/gemma-2-9b-it"
CHECKPOINT_DIR = Path("outputs/gemma_qlora_20251104_181124")  # –í–∞—à–∞ –ø–∞–ø–∫–∞!
```

## üöÄ –ó–ê–ü–£–°–ö:

### –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—É—Å–∫:

```bash
cd ~/gemma_api
conda activate gemma_api  # –∏–ª–∏ source venv/bin/activate
python api_server.py
```

### –ò–ª–∏ —á–µ—Ä–µ–∑ uvicorn —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:

```bash
uvicorn api_server:app --host 0.0.0.0 --port 8000 --workers 1
```

### –í —Ñ–æ–Ω–µ (daemon):

```bash
nohup python api_server.py > api.log 2>&1 &
```

## üåê –î–û–°–¢–£–ü –ö API:

### –ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ:
```
http://localhost:8000
```

### –° –¥—Ä—É–≥–æ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞ –≤ —Å–µ—Ç–∏:
```
http://IP_–ê–î–†–ï–°:8000
```

–£–∑–Ω–∞—Ç—å IP:
```bash
hostname -I
```

## üìä –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï VRAM:

API –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **~5-6 GB VRAM** (4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è):
- –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: ~4.5 GB
- LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã: ~0.5 GB
- Inference: ~1 GB

## ‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:

**–ù–∞ GPU:**
- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: 1-2 –º–∏–Ω—É—Ç—ã
- –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å: ~10-15 —Å–µ–∫ (–∫–æ–º–ø–∏–ª—è—Ü–∏—è CUDA)
- –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ: **3-5 —Å–µ–∫—É–Ω–¥** ‚ö°

**–ù–∞ CPU (–µ—Å–ª–∏ –Ω–µ—Ç GPU):**
- –ó–∞–≥—Ä—É–∑–∫–∞: 2-3 –º–∏–Ω—É—Ç—ã
- –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å: 30-60 —Å–µ–∫—É–Ω–¥ üêå

## üîí –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ (–¥–ª—è production):

### 1. –î–æ–±–∞–≤—å—Ç–µ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é:

```python
from fastapi.security import HTTPBearer

security = HTTPBearer()

@app.post("/predict")
async def predict(request: PredictionRequest, token: str = Depends(security)):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞
    if token != "YOUR_SECRET_TOKEN":
        raise HTTPException(401, "Unauthorized")
    ...
```

### 2. Rate limiting:

```bash
pip install slowapi

from slowapi import Limiter
limiter = Limiter(key_func=get_remote_address)

@app.post("/predict")
@limiter.limit("10/minute")
async def predict(...):
    ...
```

### 3. HTTPS (—Å nginx):

```nginx
server {
    listen 443 ssl;
    server_name your-domain.com;
    
    location / {
        proxy_pass http://localhost:8000;
    }
}
```

## üêõ TROUBLESHOOTING:

### "CUDA out of memory"
```python
# –£–º–µ–Ω—å—à–∏—Ç–µ batch size –≤ generate
outputs = model.generate(..., batch_size=1)
```

### "Address already in use"
```bash
# –ù–∞–π—Ç–∏ –∏ —É–±–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
lsof -ti:8000 | xargs kill -9
```

### "Checkpoint not found"
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏
ls outputs/gemma_qlora_*/checkpoint-*
```

### "Slow first request"
–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - CUDA kernels –∫–æ–º–ø–∏–ª–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.

## üìù –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –ß–ï–ö–ü–û–ò–ù–¢–´:

API –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **–ø–æ—Å–ª–µ–¥–Ω–∏–π checkpoint**.

–î–ª—è –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ, –∏–∑–º–µ–Ω–∏—Ç–µ –≤ `api_server.py`:

```python
# –°—Ç—Ä–æ–∫–∞ 20-22
LATEST_CHECKPOINT = Path("outputs/gemma_qlora_20251104_181124/checkpoint-7000")
```

–î–æ—Å—Ç—É–ø–Ω—ã–µ checkpoints:
- **checkpoint-1000**: epoch 0.06 (~5% quality)
- **checkpoint-3000**: epoch 0.18 (~15% quality)
- **checkpoint-7000**: epoch 0.40 (~35-40% quality) ‚Üê —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è!
- **checkpoint-17000**: epoch 1.0 (~65% quality)

## üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:

1. **–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ checkpoint-3000
2. **–î–ª—è –¥–µ–º–æ:** checkpoint-7000+
3. **–î–ª—è production:** –¥–æ–∂–¥–∏—Ç–µ—Å—å –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è (3 —ç–ø–æ—Ö–∏)

---

**–í–æ–ø—Ä–æ—Å—ã?** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: `tail -f api.log`


"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –æ–±—É—á–µ–Ω–∏—è
"""

import sys
import subprocess

def check_python_version():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ Python"""
    version = sys.version_info
    print(f"üêç Python: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 10):
        print("   ‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è Python 3.10+")
    else:
        print("   ‚úÖ –í–µ—Ä—Å–∏—è –ø–æ–¥—Ö–æ–¥–∏—Ç")
    
    return version.major >= 3 and version.minor >= 10

def check_gpu():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ GPU"""
    try:
        import torch
        
        cuda_available = torch.cuda.is_available()
        print(f"\nüéÆ CUDA: {'–î–æ—Å—Ç—É–ø–Ω–∞' if cuda_available else '–ù–µ –¥–æ—Å—Ç—É–ø–Ω–∞'}")
        
        if cuda_available:
            device_name = torch.cuda.get_device_name(0)
            total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   GPU: {device_name}")
            print(f"   VRAM: {total_memory:.1f} GB")
            
            if total_memory < 12:
                print(f"   ‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 12GB VRAM")
                print(f"   üí° –£ –≤–∞—Å {total_memory:.1f}GB - —É–º–µ–Ω—å—à–∏—Ç–µ BATCH_SIZE")
            elif total_memory < 16:
                print(f"   ‚ö†Ô∏è  16GB VRAM –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ")
            else:
                print(f"   ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏!")
            
            return True
        else:
            print("   ‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
            print("   üí° –û–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
            return False
            
    except ImportError:
        print("\n‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        return False

def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"""
    print("\nüì¶ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:")
    
    required = {
        'torch': 'PyTorch',
        'transformers': 'Transformers',
        'peft': 'PEFT',
        'bitsandbytes': 'BitsAndBytes',
        'accelerate': 'Accelerate',
        'datasets': 'Datasets',
    }
    
    all_installed = True
    
    for package, name in required.items():
        try:
            module = __import__(package)
            version = getattr(module, '__version__', 'unknown')
            print(f"   ‚úÖ {name}: {version}")
        except ImportError:
            print(f"   ‚ùå {name}: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            all_installed = False
    
    return all_installed

def check_disk_space():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ"""
    import shutil
    
    print("\nüíæ –°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ:")
    
    total, used, free = shutil.disk_usage("/")
    free_gb = free / (1024**3)
    
    print(f"   –°–≤–æ–±–æ–¥–Ω–æ: {free_gb:.1f} GB")
    
    if free_gb < 30:
        print(f"   ‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 30GB")
        print(f"   üí° –ú–æ–¥–µ–ª—å + –¥–∞—Ç–∞—Å–µ—Ç—ã + –ª–æ–≥–∏ –∑–∞–π–º—É—Ç ~20-30GB")
        return False
    else:
        print(f"   ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞")
        return True

def check_data():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    from pathlib import Path
    
    print("\nüìÇ –î–∞–Ω–Ω—ã–µ:")
    
    data_file = Path(__file__).parent.parent.parent / 'final_dataset.csv'
    
    if data_file.exists():
        size_mb = data_file.stat().st_size / (1024**2)
        print(f"   ‚úÖ final_dataset.csv –Ω–∞–π–¥–µ–Ω ({size_mb:.1f} MB)")
        return True
    else:
        print(f"   ‚ùå final_dataset.csv –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print(f"   üí° –û–∂–∏–¥–∞–µ—Ç—Å—è: {data_file}")
        return False

def main():
    print("=" * 80)
    print("üîç –ü–†–û–í–ï–†–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø –î–õ–Ø QLORA FINE-TUNING")
    print("=" * 80)
    
    checks = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    checks.append(("Python", check_python_version()))
    checks.append(("GPU", check_gpu()))
    checks.append(("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏", check_dependencies()))
    checks.append(("–î–∏—Å–∫", check_disk_space()))
    checks.append(("–î–∞–Ω–Ω—ã–µ", check_data()))
    
    # –ò—Ç–æ–≥
    print("\n" + "=" * 80)
    print("üìä –ò–¢–û–ì–ò –ü–†–û–í–ï–†–ö–ò")
    print("=" * 80)
    
    for name, status in checks:
        status_icon = "‚úÖ" if status else "‚ùå"
        print(f"{status_icon} {name}")
    
    all_passed = all(status for _, status in checks)
    
    if all_passed:
        print("\nüéâ –í—Å—ë –≥–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É –æ–±—É—á–µ–Ω–∏—è!")
        print("\nüìù –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("   1. python scripts/prepare_data.py")
        print("   2. python scripts/train_qlora.py")
    else:
        print("\n‚ö†Ô∏è  –¢—Ä–µ–±—É—é—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        if not checks[1][1]:  # GPU
            print("   - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA")
            print("   - pip install torch --index-url https://download.pytorch.org/whl/cu121")
        if not checks[2][1]:  # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            print("   - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements.txt")
        if not checks[4][1]:  # –î–∞–Ω–Ω—ã–µ
            print("   - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ final_dataset.csv –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞")
    
    print("=" * 80)

if __name__ == "__main__":
    main()


"""
Inference —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ OperCode –¥–ª—è –Ω–æ–≤—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π
"""

import torch
import json
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import re

# –ü—É—Ç–∏
BASE_DIR = Path(__file__).parent.parent
MODEL_DIR = BASE_DIR / "models"

class OperCodeClassifier:
    """–ö–ª–∞—Å—Å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–ª–∞—Ç–µ–∂–µ–π"""
    
    def __init__(self, model_path):
        self.model_path = Path(model_path)
        self.model = None
        self.tokenizer = None
        self.config = None
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path.name}...")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        with open(self.model_path / 'training_config.json', 'r') as f:
            self.config = json.load(f)
        
        # Tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        
        # Base model
        base_model = AutoModelForCausalLM.from_pretrained(
            self.config['model_name'],
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True,
        )
        
        # LoRA adapters
        self.model = PeftModel.from_pretrained(base_model, self.model_path)
        self.model = self.model.merge_and_unload()
        self.model.eval()
        
        print("   ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
    
    def predict(self, payment_comment, return_confidence=False):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ OperCode –¥–ª—è –ø–ª–∞—Ç–µ–∂–∞
        
        Args:
            payment_comment (str): –¢–µ–∫—Å—Ç –ø–ª–∞—Ç–µ–∂–∞
            return_confidence (bool): –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            
        Returns:
            int or tuple: OperCode –∏–ª–∏ (OperCode, confidence)
        """
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = f"""<start_of_turn>user
–û–ø—Ä–µ–¥–µ–ª–∏ –∫–æ–¥ –æ–ø–µ—Ä–∞—Ü–∏–∏ (OperCode) –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–∞–Ω–∫–æ–≤—Å–∫–æ–≥–æ –ø–ª–∞—Ç–µ–∂–∞:

–ü–ª–∞—Ç—ë–∂: {payment_comment}

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–¥–æ–º –æ–ø–µ—Ä–∞—Ü–∏–∏.<end_of_turn>
<start_of_turn>model
"""
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=10,
                do_sample=False,
                temperature=0.1,
                pad_token_id=self.tokenizer.eos_token_id,
                return_dict_in_generate=True,
                output_scores=True,
            )
        
        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        generated = self.tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        prompt_length = len(self.tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True))
        prediction_text = generated[prompt_length:].strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
        opercode = self._extract_opercode(prediction_text)
        
        if return_confidence:
            # –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
            confidence = self._calculate_confidence(outputs.scores)
            return opercode, confidence
        
        return opercode
    
    def _extract_opercode(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ OperCode –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        match = re.search(r'\d+', text)
        if match:
            return int(match.group())
        return None
    
    def _calculate_confidence(self, scores):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        if not scores:
            return 0.0
        
        # –ë–µ—Ä–µ–º softmax –æ—Ç –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        first_token_scores = torch.softmax(scores[0][0], dim=-1)
        confidence = first_token_scores.max().item()
        
        return confidence
    
    def predict_batch(self, payment_comments):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è batch –ø–ª–∞—Ç–µ–∂–µ–π
        
        Args:
            payment_comments (list): –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –ø–ª–∞—Ç–µ–∂–µ–π
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ OperCode
        """
        results = []
        for comment in payment_comments:
            opercode = self.predict(comment)
            results.append(opercode)
        return results

def find_latest_model():
    """–ü–æ–∏—Å–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    model_dirs = sorted(MODEL_DIR.glob("gemma_qlora_*"))
    if not model_dirs:
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ {MODEL_DIR}")
    return model_dirs[-1]

def interactive_mode(classifier):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º"""
    print("\n" + "=" * 80)
    print("üéÆ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú")
    print("=" * 80)
    print("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –ø–ª–∞—Ç–µ–∂–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
    print("-" * 80)
    
    while True:
        print("\nüí¨ –í–≤–µ–¥–∏—Ç–µ –ø–ª–∞—Ç—ë–∂:")
        payment = input("> ").strip()
        
        if payment.lower() in ['exit', 'quit', 'q']:
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        
        if not payment:
            continue
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        opercode, confidence = classifier.predict(payment, return_confidence=True)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"   OperCode: {opercode}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")

def demo_mode(classifier):
    """–î–µ–º–æ —Ä–µ–∂–∏–º —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏"""
    print("\n" + "=" * 80)
    print("üé¨ –î–ï–ú–û –†–ï–ñ–ò–ú")
    print("=" * 80)
    
    examples = [
        "'TRANSFER OF FUNDS TO OWN ACCOUNT",
        "'PURCHASE OF GOODS",
        "PAYMENT FOR SALES AGENT SERVICES BY CONT B N DD 21 10 2024",
        "OPLATA ZA TRANSPORTNYE USLUGI PO ScET U 000390",
        "POLUcATELX 'Feldman inna' ScET PODAROK NEREZIDENTU",
    ]
    
    print("\n–ü—Ä–∏–º–µ—Ä—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n")
    
    for i, example in enumerate(examples, 1):
        opercode, confidence = classifier.predict(example, return_confidence=True)
        print(f"{i}. –ü–ª–∞—Ç—ë–∂: {example[:70]}...")
        print(f"   ‚Üí OperCode: {opercode} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})\n")

def main():
    print("=" * 80)
    print("üöÄ OPERCODE CLASSIFIER - INFERENCE")
    print("=" * 80)
    
    # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏
    try:
        model_path = find_latest_model()
        print(f"\nüìÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {model_path.name}")
    except FileNotFoundError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        return
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    classifier = OperCodeClassifier(model_path)
    
    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞
    print("\nüìã –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:")
    print("   1. –î–µ–º–æ (–ø—Ä–∏–º–µ—Ä—ã)")
    print("   2. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π (–≤–≤–æ–¥ —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã)")
    print("   3. –û–±–∞")
    
    choice = input("\n–í—ã–±–æ—Ä (1/2/3): ").strip()
    
    if choice == '1':
        demo_mode(classifier)
    elif choice == '2':
        interactive_mode(classifier)
    elif choice == '3':
        demo_mode(classifier)
        interactive_mode(classifier)
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    main()

